{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suicidial Ideation Detection\n",
    "#### Ian Steenstra\n",
    "#### Social Computing\n",
    "#### April 27th, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steen\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob as tb\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, r2_score\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=('text', 'suicidal_ideation'))\n",
    "for i in range(10):\n",
    "    data = pd.concat([data, pd.read_csv('annotated_data'+str(i)+'.csv')], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>suicidal_ideation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I got a surprise gift left outside from @_toky...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>never gonna live to be a teenager</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RT @GeoffreySupran: Hi @Harvard: Even as you r...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Google cares about me :')</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Does anyone else feel like they have to commit...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  suicidal_ideation\n",
       "0  I got a surprise gift left outside from @_toky...                0.0\n",
       "1                  never gonna live to be a teenager                1.0\n",
       "2  RT @GeoffreySupran: Hi @Harvard: Even as you r...                0.0\n",
       "3                          Google cares about me :')                0.0\n",
       "4  Does anyone else feel like they have to commit...                1.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['suicidal_ideation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of yeses:  0.3998871968415116\n",
      "Percent of noes:  0.6001128031584885\n"
     ]
    }
   ],
   "source": [
    "counts = y.value_counts()\n",
    "size = y.shape[0]\n",
    "print('Percent of yeses: ', counts[1]/size)\n",
    "print('Percent of noes: ', counts[0]/size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.apply(lambda text: re.sub(r\"http\\S+\", \"\", text).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1773, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_features = []\n",
    "\n",
    "for text in X:\n",
    "    sentiment = tb(text).sentiment\n",
    "    sentiment_features.append([sentiment.polarity, sentiment.subjectivity])\n",
    "    \n",
    "sentiment_features = pd.DataFrame(sentiment_features)\n",
    "sentiment_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1773, 23187)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2)) \n",
    "tfidf_features = pd.DataFrame(tfidf.fit_transform(X).toarray())\n",
    "\n",
    "tfidf_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Absolute Words Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "absol_words = [word.lower() for word in [\n",
    "    'Absolutely',\n",
    "    'All',\n",
    "    'Always',\n",
    "    'Complete',\n",
    "    'Completely',\n",
    "    'Constant',\n",
    "    'Constantly',\n",
    "    'Definitely',\n",
    "    'Entire',\n",
    "    'Ever',\n",
    "    'Every',\n",
    "    'Everyone',\n",
    "    'Everything',\n",
    "    'Full',\n",
    "    'Must',\n",
    "    'Never',\n",
    "    'Nothing',\n",
    "    'Totally',\n",
    "    'Whole']]\n",
    "\n",
    "absol_words_syn = []\n",
    "for word in absol_words:\n",
    "    for ss in wn.synsets(word):\n",
    "        absol_words_syn.extend(ss.lemma_names())\n",
    "absol_words = list(dict.fromkeys(absol_words_syn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countWord(lst, w): \n",
    "    count = 0\n",
    "    for ele in lst: \n",
    "        if (ele == w): \n",
    "            count = count + 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1773, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absol_word_counts = []\n",
    "for text in X:\n",
    "    count = 0\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    for tok in tokens:\n",
    "        count += countWord(absol_words, tok)\n",
    "    absol_word_counts.append([count])\n",
    "    \n",
    "absol_word_counts = pd.DataFrame(absol_word_counts)\n",
    "absol_word_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below is where I use a pretrained humor detection model to test whether it would generate valuable features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steen\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "text=[]\n",
    "for sentence in X:\n",
    "    sent_word_list = nltk.word_tokenize(sentence)\n",
    "    text.append(sent_word_list)\n",
    "\n",
    "w2v = FastText(text, min_count=1)\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    sent = row['text']\n",
    "    if len(sent)!=0:\n",
    "        sent_vect = sum([w2v[w.lower()] for w in nltk.word_tokenize(sent)])/(len(sent.split())+0.001)\n",
    "    else:  \n",
    "        sent_vect = np.zeros((100,))\n",
    "    vect_record.append(sent_vect) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3         4         5         6   \\\n",
      "0 -0.712867  0.475950  0.458042 -0.055522  0.262554 -0.765900 -0.476390   \n",
      "1 -0.715446  0.474678  0.460877 -0.055684  0.263628 -0.766737 -0.477077   \n",
      "2 -0.732085  0.487082  0.470120 -0.056042  0.271327 -0.787066 -0.489229   \n",
      "3 -0.656790  0.442275  0.423596 -0.050908  0.245487 -0.710136 -0.436591   \n",
      "4 -0.724267  0.480995  0.467234 -0.057034  0.269219 -0.779788 -0.482606   \n",
      "\n",
      "         7         8         9   ...        90        91        92        93  \\\n",
      "0 -0.296177 -0.731238  0.447303  ...  0.040290  0.102925  0.421974 -0.184266   \n",
      "1 -0.297413 -0.732013  0.447009  ...  0.040072  0.102386  0.423000 -0.183198   \n",
      "2 -0.305295 -0.749801  0.458566  ...  0.043675  0.103281  0.432028 -0.189249   \n",
      "3 -0.272788 -0.674683  0.413985  ...  0.037736  0.091230  0.388590 -0.169146   \n",
      "4 -0.301063 -0.742236  0.453675  ...  0.041673  0.104214  0.428427 -0.184741   \n",
      "\n",
      "         94        95        96        97        98        99  \n",
      "0  0.679914  0.028549 -0.624621  1.117525 -0.006752  0.726008  \n",
      "1  0.680295  0.025768 -0.627894  1.116710 -0.005676  0.728102  \n",
      "2  0.697782  0.027696 -0.641816  1.146089 -0.005857  0.746072  \n",
      "3  0.628537  0.026566 -0.578813  1.030605 -0.008153  0.669468  \n",
      "4  0.690784  0.027766 -0.637208  1.134501 -0.005390  0.741245  \n",
      "\n",
      "[5 rows x 100 columns]\n",
      "(1773, 100)\n"
     ]
    }
   ],
   "source": [
    "humor_feature = pd.DataFrame(vect_record, columns=range(100))\n",
    "humor_feature.to_csv('humor_features.csv')\n",
    "print(humor_feature.head())\n",
    "print(humor_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_from_joblib = joblib.load('humor_detection_linreg.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decided not to use the humor feature because all text were classified as 0 or not humorous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humor_pred = lf_from_joblib.predict(humor_feature)\n",
    "sum(humor_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1773, 23190)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.concat([tfidf_features, sentiment_features, absol_word_counts], axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaled feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "features_scaled = min_max_scaler.fit_transform(features)\n",
    "features = pd.DataFrame(features_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training w/ GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001],'kernel': ['linear', 'rbf', 'poly']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed: 23.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001],\n",
       "                         'kernel': ['linear', 'rbf', 'poly']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(SVC(), param_grid, verbose=2, cv=3, n_jobs=-1)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=1, kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[183  28]\n",
      " [ 29 115]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.86      0.87      0.87       211\n",
      "         yes       0.80      0.80      0.80       144\n",
      "\n",
      "    accuracy                           0.84       355\n",
      "   macro avg       0.83      0.83      0.83       355\n",
      "weighted avg       0.84      0.84      0.84       355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = grid.predict(X_test)\n",
    "print(confusion_matrix(y_test,grid_predictions))\n",
    "print(classification_report(y_test,grid_predictions,target_names=['no', 'yes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.concat([tfidf_features], axis=1) # changed the features in the list\n",
    "features.shape\n",
    "\n",
    "features = features.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "features_scaled = min_max_scaler.fit_transform(features)\n",
    "features = pd.DataFrame(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.2, random_state=1234) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(C=0.1, gamma=1, kernel='linear').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.87      0.85      0.86       225\n",
      "         yes       0.75      0.78      0.77       130\n",
      "\n",
      "    accuracy                           0.83       355\n",
      "   macro avg       0.81      0.82      0.81       355\n",
      "weighted avg       0.83      0.83      0.83       355\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred,target_names=['no', 'yes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy & Precision of Features:\n",
    "- All: 83%: precision - 76% yes, 87% no\n",
    "- TF-IDF: 83%: precision - 75% yes, 87% no\n",
    "- Sentiment: 63%: precision - 0% yes, 63% no\n",
    "- Absol_Word-Count: 63%: precision - 0% yes, 63% no"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
